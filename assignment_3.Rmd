---
title: "Assignment 3"
author: "Marine Courtin"
date: "17 novembre 2017"
output: html_document
---
```{r import_pipe_operator, echo=FALSE}
`%>%` <- magrittr::`%>%`
```


```{r load_func}
source("functions.R")
```


### Exercise 1: Simple data manipulation with dplyr

+ Task A.

```{r filter_table_on_dico}
stress_shift_3dict <- dplyr::filter(stressshift::stress_shift_unamb, Dict == "W1802" | Dict == "J1917" | Dict =="C1687")
print(nrow(stress_shift_3dict))
```

Logical operators :

+ or : `|`
+ and :`&`

+ Task B.

3 ways to use packages :

+ attach it by using the `library(dplyr)` command, later on we can simply use `filter` instead of `dplyr::filter`.The problem is that there is another function filter in the stats package which is attached by default. If we attach dplyr, we risk using the dplyr::filter function instead of the stats::filter function (or we could reattach stats, and forget that we need to reuse dplyr::filter afterwards). These types of problems caused by not explicity mentionning the namespace seem pretty frequent (and it makes it hard to find the source of the problem, even when we do notice a problem).
+ using the full name `dplyr::filter` every time (no risk of mixing up functions which share the same name but a different namespace. 
+ Create a shorthand for a namespace::function. This is what we did by adding the code chunk with `%>% <- magrittr::%>%`. This imports the *forward-pipe operator* from the magrittr package. What is a forward-pipe operator you may ask ? It is an operator which allows us to propagate the result of applying a function to a variable, as the argument of the next function. Adding an example with a simpler (non-R) syntax might help :

` double(4) forward-pipe triple()` -> the first operation returns 8, which in turns becomes the argument for the second function, which returns 24.


```{r first_steps_with_pipe}
stress_shift_3dict_using_pipe <- stressshift::stress_shift_unamb %>% subset(Dict == "W1802" | Dict == "J1917" | Dict =="C1687")
identical(stress_shift_3dict, stress_shift_3dict_using_pipe)
```

+ Task C.

```{r filter_and_bind_tables}
stress_shift_3dict_nouns <- stress_shift_3dict_using_pipe %>% dplyr::filter(Category=="Noun")
stress_shift_3dict_verbs <- stress_shift_3dict_using_pipe %>% dplyr::filter(Category=="Verb")
# Binding the two tables
stress_shift_3dict_using_bind <- stress_shift_3dict_nouns %>% dplyr::bind_rows(stress_shift_3dict_verbs)
# Change the order or arguments
stress_shift_3dict_using_bind_reversed <- stress_shift_3dict_verbs %>% dplyr::bind_rows(stress_shift_3dict_nouns)
# Testing if tables are identical
print(stress_shift_3dict %>% identical(stress_shift_3dict_using_bind))
print(stress_shift_3dict %>% identical(stress_shift_3dict_using_bind_reversed))
```

The differences between the two tables means that in one table rows where the Category is "Noun" will appear before rows where the Category is "Verb", while it is the opposite in the other one. Normally, if we use a function to randomize our draws from the table, this shouldn't matter. However, if we use set.seed() if think it could matter since we'll expect to get the same "random" draws every time, which we won't if we are using both tables at the same time. Therefore it would probably be best to use one of the tables consistently. 

+ Task D

```{r transform_sub_tables_join}
stress_shift_nouns_renamed <- stressshift::stress_shift_unamb %>%
  dplyr::filter(Category == "Noun") %>%
  dplyr::select(Word, Dict, Syllable) %>%
  dplyr::rename(Syllable_Noun = Syllable)
print(nrow(stress_shift_nouns_renamed))
stress_shift_verbs_renamed <- stressshift::stress_shift_unamb %>%
  dplyr::filter(Category == "Verb") %>%
  dplyr::select(Word, Dict, Syllable) %>%
  dplyr::rename(Syllable_Verb = Syllable)
print(nrow(stress_shift_verbs_renamed))
stress_shift_wide <- stress_shift_nouns_renamed %>% dplyr::inner_join(stress_shift_verbs_renamed)
```

The function dplyr::inner_join is used to find rows where the values present in table 1 and table 2 match. Whenever such as row is found, additional columns which are found only in one of the two tables are added. Here's an example :

Table 1:

Fruit | Prototypical_color | Season
------------ | -------------| -------------
Apple | red | summer
Orange | orange | spring

Table 2 :

Fruit | Size | Season
------------ | -------------| -------------
Apple | medium | autumn
Orange | medium | spring
Blueberry | small | summer

Will result in Table 3 :

Fruit | Prototypical_color | Size | Season
------------ | -------------| -------------| -------------|
Orange | orange | medium | spring

Our resulting table therefore has fewer rows because not all rows have matching values in both tables (Blueberry does not exist in table 1, Apple has contradictory values in table 1 and 2). The same applies for our stress_shift_wide table. Rows with matching values for the columns present in both tables are selected, and the columns present in only table 1 (Syllable_Noun) and in table 2 (Syllable_Verb) are added as well. This means that we are going to be able to compare stressed syllables for both noun and verb which share otherwise the same informations. 

+ Task E.


```{r plot_noun_verb_stress_distrib}
ggplot2::aes(x=Category, fill=Syllable) %>%
  ggplot2::ggplot(stressshift::stress_shift_unamb,.) +
  ggplot2::geom_bar(position="dodge", colour="black") + 
  ggplot2::scale_fill_brewer(palette="Dark2")

```

+ Task F.

```{r summarize_incomplete_table}


stress_shift_byword <- stress_shift_wide %>%
  dplyr::group_by(Word) %>%
  dplyr::summarize(Noun_Percent_Syll_1=sum(Syllable_Noun=="Syllable 1")/n(), Verb_Percent_Syll_1=sum(Syllable_Verb=="Syllable 1")/n())
print(stress_shift_byword)

if(nrow(stress_shift_byword)==149) {
      print("Il y a bien 149 lignes")
    } else {
      print("ProblÃ¨me : il n'y a pas 149 lignes")
    }
```


+ Task G.

```{r plot_incomplete_table_}
stress_shift_byword %>% 
  ggplot2::ggplot(ggplot2::aes(Noun_Percent_Syll_1, Verb_Percent_Syll_1)) +
  ggplot2::geom_point(alpha = 0.5) +
  ggplot2::scale_fill_brewer(palette="Dark2") +
  ggplot2::labs(title="Freq of 1st syllable stress for verbs according to same property for its noun")
```

+ Task H.

```{r summarize_full_table}
stress_shift_byword_all <- stressshift::stress_shift_unamb %>%
  dplyr::filter(Category == "Verb"|Category =="Noun") %>%
  dplyr::select(Word, Dict, Syllable, Category) %>%
  dplyr::group_by(Word) %>%
  dplyr::summarize(Noun_Percent_Syll_1=sum(Syllable=="Syllable 1" & Category=="Noun")/sum(Syllable=="Syllable 1"|Syllable=="Syllable 2" & Category=="Noun"), Verb_Percent_Syll_1=sum(Syllable=="Syllable 1" & Category=="Verb")/sum(Syllable=="Syllable 1"|Syllable=="Syllable 2" & Category=="Verb"))
print(stress_shift_byword_all)
```


### Exercise 2 : A permutation test for categorical data


+ Task A.
```{r compute_difference_in_proportion}
test_statistic <- difference_in_proportion(stressshift::stress_shift_unamb, "Syllable", "Category", "Noun", "Verb", "Syllable 1")

print(test_statistic)
```


+ Task B.

```{r permutation_test}
if(!exists(".Random.seed")) set.seed(NULL)
previous_seed <- .Random.seed
set.seed(1)
ptest_stress <- permutation_twogroups(stressshift::stress_shift_unamb,"Syllable", "Category",
                                      "Noun", "Verb",difference_in_proportion,n_samples=99,"Syllable 1")
set.seed(previous_seed)
permutation_pvalue_right(ptest_stress)
```

```{r plotting_permutation_tests}
permuted <- tibble::as_tibble(ptest_stress["permuted"])
original <- tibble::as_tibble(ptest_stress["observed"])
permuted %>%
  # what par of the data do we want to plot
  ggplot2::ggplot(.,ggplot2::aes(x=., y=(..count..))) +
  # how is the histogram going to look like
  ggplot2::geom_histogram(colour="black", fill="#FFCC66", binwidth = 0.005) +
  # adding the observed measure (unfortunately this messes up the binwidth)
  ggplot2::geom_vline(ggplot2::aes(xintercept=original),colour="black")
```


### Exercise 3: Simulating new cases like our own



+ Task A.

```{r build_data_frame_with_rbinom}
proportion_n_syll_1 <- stressshift::stress_shift_unamb %>%
  dplyr::filter(.,Category=="Noun" & Syllable =="Syllable 1") %>%
  nrow(.) / nrow(dplyr::filter(stressshift::stress_shift_unamb, Category=="Noun"))


proportion_v_syll_1 <- stressshift::stress_shift_unamb %>%
  dplyr::filter(.,Category=="Verb" & Syllable =="Syllable 1") %>%
  nrow(.) / nrow(dplyr::filter(stressshift::stress_shift_unamb, Category=="Verb"))

nb_n_observations <- nrow(dplyr::filter(stressshift::stress_shift_unamb, Category=="Noun"))
nb_v_observations <- nrow(dplyr::filter(stressshift::stress_shift_unamb, Category=="Verb"))

Noun_N_Syll_1 <- rbinom(1000, prob=proportion_n_syll_1, size=nb_n_observations)
Verb_N_Syll_1 <- rbinom(1000, prob=proportion_v_syll_1, size=nb_v_observations)



stress_shift_replications <- data.frame(
  "Noun_Percent_Syll_1" = Noun_N_Syll_1,
  "Verb_Percent_Syll_1" = Verb_N_Syll_1,
  "Replication" = paste0("R", sprintf("%04d", 1:1000)),
  "Difference_in_Proportion" = Noun_N_Syll_1/6506 - Verb_N_Syll_1/6732
)

```

```{r plot_data_test_statistics_with_rbinom}
permuted <- tibble::as_tibble(stress_shift_replications["Difference_in_Proportion"])
# original ne change pas
permuted %>%
  # what par of the data do we want to plot
  ggplot2::ggplot(.,ggplot2::aes(x=., y=(..count..))) +
  # how is the histogram going to look like
  ggplot2::geom_histogram(colour="black", fill="#FFCC66", binwidth = 0.005) +
  # adding the observed measure (unfortunately this messes up the binwidth)
  ggplot2::geom_vline(ggplot2::aes(xintercept=original),colour="black") + 
  ggplot2::xlim(c(-0.1, 0.8))

# The original one
permuted <- tibble::as_tibble(ptest_stress["permuted"])
permuted %>%
  # what par of the data do we want to plot
  ggplot2::ggplot(.,ggplot2::aes(x=., y=(..count..))) +
  # how is the histogram going to look like
  ggplot2::geom_histogram(colour="black", fill="#FFCC66", binwidth = 0.005) +
  # adding the observed measure (unfortunately this messes up the binwidth)
  ggplot2::geom_vline(ggplot2::aes(xintercept=original),colour="black") +
  ggplot2::xlim(c(-0.1, 0.8))
```


For the 1st histogram, we looked at the proportion of 1st syllable stressed nouns and verbs. Based on these proportions, we created binomial distributions for both noun and verbs. Each of these distribution is based on 1000 observations, with each observation having a number of trials equal to the number of nouns/verbs in the original data. We then computed the difference in proportions for each of these observations and plotted the result. These results are the compared to the result observed in our original data (the black line).

The 2nd histogram plots the distribution obtained by measuring the differences in proportion of nouns vs verbs with 1st syllable stress, obtained by creating 99 permutation tests. These results obtained by permutation (i.e a test which creates two groups of observations which share the same source of variability, which represents the hypothesis of same distribution) are compared to the observed result (the black line). Since this distribution is supposed to represent a null hypothesis case, with no difference between the 2 groups, the distribution is centered around 0 and approximately symmetric around this center.

We can see that our observed result seems to occur arround the middle of the distribution generated from the differences in proportions of 1st stress syllable between the noun and verb population created with a binomial distribution. This corresponds to the *expected value* EX(X). Our binomial variable X represents the number of times the difference in proportion takes a value x in the interval [0:200] (X=0 if the difference in proportion z respects : 0â¤z<0.005, X=1 if the difference in proportion z respects : 0.005â¤z<0.01 etc...). Our observed result might therefore indicate that our original noun data and verb data respected binomial distributions (with the number of 1st syllable stress for each population a consequence of this distribution, and our difference in proportions a difference between the expected values for noun and verbs)


+ Task B.


```{r initial_stress_shift_repli, cache=T}
stress_shift_replications <- stress_shift_replications %>%
  dplyr::mutate(
    Permutation_Pvalue=v_pdp_pvalue_right(Noun_N_Syll_1, Verb_N_Syll_1,
                                          nb_n_observations,
                                          nb_v_observations,
                                          n_samples=99))
```


+ Task C.

Re-do this power analysis under six conditions (it would be a lot smarter to create a function to replicate the test without having these huge chunks of code which are a. likely to contain errors, b. not very human-friendly c. use lots of temporary variables instead of `%>%`, but I don't have enough time to do so)



+ with one tenth the number of observations in each group (651 noun and 673 verb observations)
```{r first_condition, cache=T}
Noun_N_Syll_2 <- rbinom(1000, prob=proportion_n_syll_1, size=651)
Verb_N_Syll_2 <- rbinom(1000, prob=proportion_v_syll_1, size=673)

stress_shift_replications_2 <- data.frame(
  "Noun_Percent_Syll_1" = Noun_N_Syll_2,
  "Verb_Percent_Syll_1" = Verb_N_Syll_2,
  "Replication" = paste0("R", sprintf("%04d", 1:1000)),
  "Difference_in_Proportion" = Noun_N_Syll_2/651 - Verb_N_Syll_2/673
)

stress_shift_replications_2 <- stress_shift_replications_2 %>%
  dplyr::mutate(
    Permutation_Pvalue=v_pdp_pvalue_right(Noun_N_Syll_2, Verb_N_Syll_2,
                                          651,
                                          673,
                                          n_samples=99))
```

+ with the same overall number of observations, but with one tenth as many observations for verbs as for nouns (12034 noun and 1204 verb observations)
```{r second_condition, cache=T}
Noun_N_Syll_3 <- rbinom(1000, prob=proportion_n_syll_1, size=12034)
Verb_N_Syll_3 <- rbinom(1000, prob=proportion_v_syll_1, size=1204)

stress_shift_replications_3 <- data.frame(
  "Noun_Percent_Syll_1" = Noun_N_Syll_3,
  "Verb_Percent_Syll_1" = Verb_N_Syll_3,
  "Replication" = paste0("R", sprintf("%04d", 1:1000)),
  "Difference_in_Proportion" = Noun_N_Syll_3/12034 - Verb_N_Syll_3/1204
)

stress_shift_replications_3 <- stress_shift_replications_3 %>%
  dplyr::mutate(
    Permutation_Pvalue=v_pdp_pvalue_right(Noun_N_Syll_3, Verb_N_Syll_3,
                                          12034,
                                          1204,
                                          n_samples=99))
```

+ with a total of only 33 observations (16 noun observations and 17 verb observations)
```{r third_condition, cache=T}
Noun_N_Syll_4 <- rbinom(1000, prob=proportion_n_syll_1, size=16)
Verb_N_Syll_4 <- rbinom(1000, prob=proportion_v_syll_1, size=17)

stress_shift_replications_4 <- data.frame(
  "Noun_Percent_Syll_1" = Noun_N_Syll_4,
  "Verb_Percent_Syll_1" = Verb_N_Syll_4,
  "Replication" = paste0("R", sprintf("%04d", 1:1000)),
  "Difference_in_Proportion" = Noun_N_Syll_4/16 - Verb_N_Syll_4/17
)

stress_shift_replications_4 <- stress_shift_replications_4 %>%
  dplyr::mutate(
    Permutation_Pvalue=v_pdp_pvalue_right(Noun_N_Syll_4, Verb_N_Syll_4,
                                          16,
                                          17,
                                          n_samples=99))
```


+ with a total of 33 observations, but with one tenth as many observations for verbs as for nouns (30 noun observations and 3 verb observations)
```{r fourth_condition, cache=T}
Noun_N_Syll_5 <- rbinom(1000, prob=proportion_n_syll_1, size=30)
Verb_N_Syll_5 <- rbinom(1000, prob=proportion_v_syll_1, size=3)

stress_shift_replications_5 <- data.frame(
  "Noun_Percent_Syll_1" = Noun_N_Syll_5,
  "Verb_Percent_Syll_1" = Verb_N_Syll_5,
  "Replication" = paste0("R", sprintf("%04d", 1:1000)),
  "Difference_in_Proportion" = Noun_N_Syll_5/30 - Verb_N_Syll_5/3
)

stress_shift_replications_5 <- stress_shift_replications_5 %>%
  dplyr::mutate(
    Permutation_Pvalue=v_pdp_pvalue_right(Noun_N_Syll_5, Verb_N_Syll_5,
                                          30,
                                          3,
                                          n_samples=99))
```

+ with one tenth the number of observations, and a probability of âSyllable 1â of 0.52 for nouns and 0.48 for verbs
```{r fifth_condition, cache=T}

# on recrÃ©Ã© des donnÃ©es avec les proba diffÃ©rentes
Noun_N_Syll_6 <- rbinom(1000, prob=0.52, size=651)
Verb_N_Syll_6 <- rbinom(1000, prob=0.48, size=673)

stress_shift_replications_6 <- data.frame(
  "Noun_Percent_Syll_1" = Noun_N_Syll_6,
  "Verb_Percent_Syll_1" = Verb_N_Syll_6,
  "Replication" = paste0("R", sprintf("%04d", 1:1000)),
  "Difference_in_Proportion" = Noun_N_Syll_6/651 - Verb_N_Syll_6/673
)

stress_shift_replications_6 <- stress_shift_replications_6 %>%
  dplyr::mutate(
    Permutation_Pvalue=v_pdp_pvalue_right(Noun_N_Syll_6, Verb_N_Syll_6,
                                          651,
                                          673,
                                          n_samples=99))
```

+ with the same original numbers of observations, and new underlying distributions in the two groups: a probability
of âSyllable 1â of 0.52 for nouns and 0.48 for verbs

```{r sixth_condition, cache=T}
Noun_N_Syll_7 <- rbinom(1000, prob=0.52, size=nb_n_observations)
Verb_N_Syll_7 <- rbinom(1000, prob=0.48, size=nb_v_observations)

stress_shift_replications_7 <- data.frame(
  "Noun_Percent_Syll_1" = Noun_N_Syll_7,
  "Verb_Percent_Syll_1" = Verb_N_Syll_7,
  "Replication" = paste0("R", sprintf("%04d", 1:1000)),
  "Difference_in_Proportion" = Noun_N_Syll_7/nb_n_observations - Verb_N_Syll_7/nb_v_observations
)

stress_shift_replications_7 <- stress_shift_replications_7 %>%
  dplyr::mutate(
    Permutation_Pvalue=v_pdp_pvalue_right(Noun_N_Syll_7, Verb_N_Syll_7,
                                          nb_n_observations,
                                          nb_v_observations,
                                          n_samples=99))
```

# TO CHANGE

```{r, eval=FALSE, evaluate=F, include=FALSE}
#Give the estimated statistical power at the 0.05 level under each of these conditions. Discuss the results.

#Estimated power (1 - Type 2 error rate) for a test at the 0.05 significance level:
1 - sum(pvals > 0.05)/N_EXPERIMENTS
```

# Exercise 4: Testing the independence assumption

```{r, cache=T}
# just a recap of the arguments :
# pearson_x2_stat's arg : d, var, grouping_var
# permutation test's arg : d, var_to_permute, statistic, n_samples=9999, ...
permutation_pearson <- permutation_test(dplyr::filter(stressshift::stress_shift_unamb, Category=="Noun"), "Syllable", pearson_x2_stat, n_samples=99, "Syllable", "Word")
#print(permutation_pearson)

```
